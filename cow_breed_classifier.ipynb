{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ni175/cow-breeding-model/blob/main/cow_breed_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit opencv-python numpy tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gEhXl9n3X3fI",
        "outputId": "653079ef-9910-426b-8825-89ea17d34f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "def create_model(num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Data preparation\n",
        "def train_model(dataset_path):\n",
        "    datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        validation_split=0.2,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    validation_generator = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    num_classes = len(train_generator.class_indices)\n",
        "    model = create_model(num_classes)\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        epochs=10,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.save('cow_breed_model_resnet.h5')\n",
        "    print(\"Model saved as 'cow_breed_model_resnet.h5'\")\n",
        "    class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
        "    np.save('class_labels_resnet.npy', class_labels)\n",
        "    print(\"Class labels saved as 'class_labels_resnet.npy'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = \"/content/drive/MyDrive/Cowdataset/Cow Breed Dataset\"\n",
        "    train_model(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcXO-7XxX6-k",
        "outputId": "781b65a9-b4e5-4b70-eb62-45ebd7cee020",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1734 images belonging to 12 classes.\n",
            "Found 428 images belonging to 12 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 11s/step - accuracy: 0.1098 - loss: 3.0631 - val_accuracy: 0.2243 - val_loss: 2.2329\n",
            "Epoch 2/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 8s/step - accuracy: 0.2339 - loss: 2.2648 - val_accuracy: 0.2897 - val_loss: 2.1334\n",
            "Epoch 3/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 8s/step - accuracy: 0.2686 - loss: 2.1903 - val_accuracy: 0.3294 - val_loss: 2.0215\n",
            "Epoch 4/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 8s/step - accuracy: 0.3199 - loss: 2.0550 - val_accuracy: 0.3575 - val_loss: 1.9386\n",
            "Epoch 5/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 8s/step - accuracy: 0.3152 - loss: 2.0161 - val_accuracy: 0.3879 - val_loss: 1.8482\n",
            "Epoch 6/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 8s/step - accuracy: 0.3446 - loss: 1.9111 - val_accuracy: 0.3855 - val_loss: 1.8238\n",
            "Epoch 7/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 8s/step - accuracy: 0.3986 - loss: 1.8257 - val_accuracy: 0.4252 - val_loss: 1.7358\n",
            "Epoch 8/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 8s/step - accuracy: 0.3899 - loss: 1.8056 - val_accuracy: 0.4182 - val_loss: 1.6966\n",
            "Epoch 9/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 8s/step - accuracy: 0.4342 - loss: 1.6969 - val_accuracy: 0.4463 - val_loss: 1.6496\n",
            "Epoch 10/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 8s/step - accuracy: 0.4254 - loss: 1.7117 - val_accuracy: 0.4579 - val_loss: 1.6557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'cow_breed_model_resnet.h5'\n",
            "Class labels saved as 'class_labels_resnet.npy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pandas numpy matplotlib seaborn plotly pillow tensorflow scikit-learn dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dlvmIwg6MgEk",
        "outputId": "08a4f209-1dda-45e2-d706-73f750a82568"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading streamlit-1.44.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: watchdog, python-dotenv, pydeck, dotenv, streamlit\n",
            "Successfully installed dotenv-0.9.9 pydeck-0.9.1 python-dotenv-1.1.0 streamlit-1.44.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tnhczpPAMjh4",
        "outputId": "c6993c42-87bd-482d-832f-ba53422232b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client(api_key='AIzaSyD2qQS2np64IJ2A-9gE3HSd5nW8ZacmUAk')\n",
        "response = client.models.generate_content(\n",
        "    model='gemini-2.0-flash', contents='How does RLHF work?'\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d5-65_X9MmQ-",
        "outputId": "1facb6dd-1fda-46b3-e688-dacb90f1a9d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RLHF, or Reinforcement Learning from Human Feedback, is a technique used to fine-tune large language models (LLMs) to better align with human preferences and intentions. It's essentially about teaching the LLM to understand what humans *actually want* from it, not just what it's statistically likely to generate based on the training data.\n",
            "\n",
            "Here's a breakdown of the key steps involved in RLHF:\n",
            "\n",
            "**1. Supervised Fine-Tuning (SFT):**\n",
            "\n",
            "*   **Purpose:**  To create a base model that can perform the desired tasks reasonably well. Think of it as giving the model a good starting point.\n",
            "*   **Process:**\n",
            "    *   Gather a dataset of prompts and desired responses. This dataset is often created or curated by humans who provide high-quality examples of how the model should behave.\n",
            "    *   Fine-tune a pre-trained LLM (like a version of GPT, LaMDA, or similar) on this dataset. This means training the model to predict the desired responses given the prompts in the dataset.\n",
            "    *   **Output:** A Supervised Fine-Tuned (SFT) model that generates responses closer to human expectations compared to the initial pre-trained model.\n",
            "\n",
            "**2. Training a Reward Model (RM):**\n",
            "\n",
            "*   **Purpose:** To create a model that can predict how much a human would prefer one response over another for a given prompt. This is the key innovation that allows incorporating human preferences automatically.\n",
            "*   **Process:**\n",
            "    *   **Data Collection:**  Human annotators (labelers) are presented with a prompt and multiple different responses generated by the SFT model (usually 4-9 responses).\n",
            "    *   **Ranking/Rating:** The annotators rank or rate the responses based on various criteria, such as helpfulness, truthfulness, harmlessness, and overall quality. Importantly, they provide *relative* comparisons rather than absolute scores. This comparison helps the RM learn subtle differences in preference. Common methods:\n",
            "        *   **Ranking:**  Annotators rank the responses from best to worst. This is often preferred because it provides more informative data than just rating.\n",
            "        *   **Pairwise Comparison:** Annotators are presented with two responses and asked to choose which one they prefer. This is easier for annotators than ranking multiple options.\n",
            "        *   **Ratings:** Annotators rate responses on a scale (e.g., 1-5 stars). This is less common as it is less informative.\n",
            "    *   **Reward Model Training:**  The RM is trained on this ranked or rated data.  It learns to predict the reward score for a given prompt and response.  The training objective is to predict which response a human would prefer based on the features of the prompt and response.  The RM is often trained using a loss function that encourages it to assign higher scores to the preferred responses and lower scores to the less preferred responses.\n",
            "    *   **Common Reward Model Architectures:**  RMs are often Transformer-based models, similar to the LLMs they are rewarding.\n",
            "    *   **Output:**  A trained Reward Model (RM) that can estimate the human preference for a given prompt and response.\n",
            "\n",
            "**3. Reinforcement Learning (RL):**\n",
            "\n",
            "*   **Purpose:** To fine-tune the SFT model to maximize the reward predicted by the Reward Model. In other words, train the model to generate responses that the RM believes humans will prefer.\n",
            "*   **Process:**\n",
            "    *   **Agent (Policy):** The SFT model acts as the agent.\n",
            "    *   **Environment:** The environment is the task of generating responses to prompts.\n",
            "    *   **Action:** The agent takes an action by generating a response to a given prompt.\n",
            "    *   **Reward:** The Reward Model provides a reward based on the generated response. The reward is typically the score predicted by the RM for that prompt and response.  A penalty is often added for deviating too far from the original SFT model's behavior (to prevent catastrophic forgetting or undesirable side effects).\n",
            "    *   **Learning Algorithm:**  A reinforcement learning algorithm (typically Proximal Policy Optimization - PPO) is used to update the agent's policy (the SFT model's parameters) based on the rewards received.  PPO encourages the agent to explore new actions while also staying close to the previous policy, which helps to stabilize training.\n",
            "    *   **Output:**  A fine-tuned LLM that generates responses that are more aligned with human preferences as judged by the Reward Model.\n",
            "\n",
            "**In summary, RLHF works in these stages:**\n",
            "\n",
            "1.  **SFT (Supervised Fine-Tuning):** Get a base model that's reasonably good at the task.\n",
            "2.  **RM (Reward Model) Training:** Teach a model to predict what humans prefer.\n",
            "3.  **RL (Reinforcement Learning):** Use the reward model to fine-tune the SFT model, encouraging it to generate responses that maximize the predicted human preference.\n",
            "\n",
            "**Key Advantages of RLHF:**\n",
            "\n",
            "*   **Aligns with Human Preferences:**  Moves beyond just predicting the next word and focuses on generating responses that are actually helpful, truthful, and harmless.\n",
            "*   **Reduces Harmful Outputs:** Helps to mitigate biases and generate less toxic or inappropriate content.\n",
            "*   **Improves Conversational Abilities:** Enables models to have more natural and engaging conversations.\n",
            "*   **Customization:**  RLHF allows for customization of the model's behavior based on specific preferences and values.\n",
            "\n",
            "**Challenges of RLHF:**\n",
            "\n",
            "*   **Costly Data Collection:**  Gathering high-quality human feedback is expensive and time-consuming.\n",
            "*   **Subjectivity of Human Preferences:** Human preferences can be subjective and inconsistent, making it challenging to train a robust Reward Model.\n",
            "*   **Reward Hacking:** The model might find ways to exploit the Reward Model to get high rewards without actually improving the quality of the responses.\n",
            "*   **Instability:** RL training can be unstable and require careful tuning of hyperparameters.\n",
            "*   **Bias in Human Feedback:**  The annotators providing feedback can introduce their own biases, which can then be learned by the model.\n",
            "*   **Scalability:** Scaling RLHF to very large models and datasets can be computationally expensive.\n",
            "*   **Distribution Shift:** The RM is trained on the output of the SFT model, but the RL training changes the model's behavior, potentially leading to a distribution shift that can degrade the RM's performance.\n",
            "\n",
            "**Applications of RLHF:**\n",
            "\n",
            "*   **Chatbots:** Creating more engaging and helpful chatbots.\n",
            "*   **Text Summarization:** Generating more accurate and informative summaries.\n",
            "*   **Content Generation:**  Producing higher-quality and more relevant content.\n",
            "*   **Code Generation:**  Generating code that is more likely to be correct and efficient.\n",
            "\n",
            "RLHF is a powerful technique for aligning LLMs with human values and preferences, but it also presents significant challenges. Ongoing research is focused on addressing these challenges to make RLHF more efficient, robust, and scalable.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import io\n",
        "import base64\n",
        "import re\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "GOOGLE_API_KEY = os.getenv(\"AIzaSyD2qQS2np64IJ2A-9gE3HSd5nW8ZacmUAk\")  # Use .env file for security\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize Gemini model\n",
        "gemini_model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Load trained model and class labels\n",
        "model = load_model('cow_breed_model_resnet.h5')\n",
        "class_labels = np.load('class_labels_resnet.npy', allow_pickle=True).item()\n",
        "\n",
        "# New breed database based on provided data\n",
        "breed_data = {\n",
        "    \"Sibbi\": {\n",
        "        \"color\": \"Dark brown\",\n",
        "        \"weight\": 450,\n",
        "        \"height\": 125,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 4, \"Milk Fat\": 5.5, \"Milk Protein\": 3.3, \"Feed Efficiency\": 1.3,\n",
        "            \"Disease Resistance\": 9, \"Heat Tolerance\": 10, \"Cold Tolerance\": 4,\n",
        "            \"Fertility\": 8, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 8, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 9, \"Longevity\": 13, \"Climate Adaptability\": 9\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 100, \"Kankarej\": 120, \"Fresian\": 200, \"Brahman\": 180}\n",
        "    },\n",
        "    \"Sahiwal\": {\n",
        "        \"color\": \"Reddish-brown with white patches\",\n",
        "        \"weight\": 500,\n",
        "        \"height\": 130,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 12, \"Milk Fat\": 4.8, \"Milk Protein\": 3.5, \"Feed Efficiency\": 1.5,\n",
        "            \"Disease Resistance\": 10, \"Heat Tolerance\": 10, \"Cold Tolerance\": 5,\n",
        "            \"Fertility\": 9, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 9, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 9, \"Longevity\": 14, \"Climate Adaptability\": 10\n",
        "        },\n",
        "        \"genetic_distance\": {\"Kankarej\": 150, \"Fresian\": 200, \"Brahman\": 220, \"Cholistani\": 100}\n",
        "    },\n",
        "    \"Sahiwal Cross\": {\n",
        "        \"color\": \"Reddish-brown with white patches\",\n",
        "        \"weight\": 480,\n",
        "        \"height\": 128,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 10, \"Milk Fat\": 4.5, \"Milk Protein\": 3.4, \"Feed Efficiency\": 1.4,\n",
        "            \"Disease Resistance\": 8, \"Heat Tolerance\": 9, \"Cold Tolerance\": 6,\n",
        "            \"Fertility\": 8, \"Calving Ease\": 9, \"Mothering Ability\": 8, \"Temperament\": 7, \"Grazing Ability\": 8,\n",
        "            \"Strength\": 8, \"Longevity\": 11, \"Climate Adaptability\": 9\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 50, \"Kankarej\": 80, \"Fresian\": 180, \"Brahman\": 160}\n",
        "    },\n",
        "    \"Kankrej\": {\n",
        "        \"color\": \"Grey\",\n",
        "        \"weight\": 550,\n",
        "        \"height\": 135,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 8, \"Milk Fat\": 5.2, \"Milk Protein\": 3.3, \"Feed Efficiency\": 1.4,\n",
        "            \"Disease Resistance\": 9, \"Heat Tolerance\": 10, \"Cold Tolerance\": 6,\n",
        "            \"Fertility\": 9, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 8, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 10, \"Longevity\": 13, \"Climate Adaptability\": 10\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 150, \"Fresian\": 210, \"Brahman\": 200, \"Cholistani\": 120}\n",
        "    },\n",
        "    \"Friesian Cross\": {\n",
        "        \"color\": \"Black and white\",\n",
        "        \"weight\": 580,\n",
        "        \"height\": 138,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 20, \"Milk Fat\": 3.8, \"Milk Protein\": 3.2, \"Feed Efficiency\": 1.6,\n",
        "            \"Disease Resistance\": 6, \"Heat Tolerance\": 7, \"Cold Tolerance\": 7,\n",
        "            \"Fertility\": 7, \"Calving Ease\": 8, \"Mothering Ability\": 7, \"Temperament\": 7, \"Grazing Ability\": 7,\n",
        "            \"Strength\": 7, \"Longevity\": 9, \"Climate Adaptability\": 8\n",
        "        },\n",
        "        \"genetic_distance\": {\"Fresian\": 50, \"Sahiwal\": 180, \"Brahman\": 200, \"Cholistani\": 190}\n",
        "    },\n",
        "    \"Friesian\": {\n",
        "        \"color\": \"Black and white\",\n",
        "        \"weight\": 600,\n",
        "        \"height\": 140,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 30, \"Milk Fat\": 3.4, \"Milk Protein\": 3.1, \"Feed Efficiency\": 1.7,\n",
        "            \"Disease Resistance\": 5, \"Heat Tolerance\": 6, \"Cold Tolerance\": 8,\n",
        "            \"Fertility\": 6, \"Calving Ease\": 7, \"Mothering Ability\": 7, \"Temperament\": 6, \"Grazing Ability\": 6,\n",
        "            \"Strength\": 6, \"Longevity\": 8, \"Climate Adaptability\": 7\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 200, \"Kankarej\": 210, \"Brahman\": 220, \"Cholistani\": 200}\n",
        "    },\n",
        "    \"Dhani\": {\n",
        "        \"color\": \"White\",\n",
        "        \"weight\": 520,\n",
        "        \"height\": 132,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 5, \"Milk Fat\": 5.8, \"Milk Protein\": 3.6, \"Feed Efficiency\": 1.2,\n",
        "            \"Disease Resistance\": 9, \"Heat Tolerance\": 9, \"Cold Tolerance\": 5,\n",
        "            \"Fertility\": 9, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 8, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 9, \"Longevity\": 12, \"Climate Adaptability\": 9\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 120, \"Kankarej\": 100, \"Fresian\": 200, \"Brahman\": 180}\n",
        "    },\n",
        "    \"Cholistani Cross\": {\n",
        "        \"color\": \"Light brown\",\n",
        "        \"weight\": 470,\n",
        "        \"height\": 127,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 9, \"Milk Fat\": 4.6, \"Milk Protein\": 3.4, \"Feed Efficiency\": 1.4,\n",
        "            \"Disease Resistance\": 8, \"Heat Tolerance\": 9, \"Cold Tolerance\": 6,\n",
        "            \"Fertility\": 8, \"Calving Ease\": 9, \"Mothering Ability\": 8, \"Temperament\": 8, \"Grazing Ability\": 8,\n",
        "            \"Strength\": 8, \"Longevity\": 11, \"Climate Adaptability\": 9\n",
        "        },\n",
        "        \"genetic_distance\": {\"Cholistani\": 50, \"Sahiwal\": 80, \"Fresian\": 190, \"Brahman\": 170}\n",
        "    },\n",
        "    \"Cholistani\": {\n",
        "        \"color\": \"Light brown\",\n",
        "        \"weight\": 460,\n",
        "        \"height\": 125,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 13, \"Milk Fat\": 4.9, \"Milk Protein\": 3.5, \"Feed Efficiency\": 1.5,\n",
        "            \"Disease Resistance\": 9, \"Heat Tolerance\": 10, \"Cold Tolerance\": 5,\n",
        "            \"Fertility\": 9, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 9, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 9, \"Longevity\": 13, \"Climate Adaptability\": 10\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 100, \"Kankarej\": 120, \"Fresian\": 200, \"Brahman\": 180}\n",
        "    },\n",
        "    \"Brahman\": {\n",
        "        \"color\": \"Grey with hump\",\n",
        "        \"weight\": 560,\n",
        "        \"height\": 136,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 7, \"Milk Fat\": 5.0, \"Milk Protein\": 3.3, \"Feed Efficiency\": 1.3,\n",
        "            \"Disease Resistance\": 10, \"Heat Tolerance\": 10, \"Cold Tolerance\": 6,\n",
        "            \"Fertility\": 9, \"Calving Ease\": 9, \"Mothering Ability\": 9, \"Temperament\": 8, \"Grazing Ability\": 9,\n",
        "            \"Strength\": 10, \"Longevity\": 14, \"Climate Adaptability\": 10\n",
        "        },\n",
        "        \"genetic_distance\": {\"Sahiwal\": 220, \"Kankarej\": 200, \"Fresian\": 220, \"Cholistani\": 180}\n",
        "    },\n",
        "    \"Brahman Cross\": {\n",
        "        \"color\": \"Grey with hump\",\n",
        "        \"weight\": 540,\n",
        "        \"height\": 134,\n",
        "        \"traits\": {\n",
        "            \"Milk Production\": 10, \"Milk Fat\": 4.7, \"Milk Protein\": 3.4, \"Feed Efficiency\": 1.4,\n",
        "            \"Disease Resistance\": 9, \"Heat Tolerance\": 9, \"Cold Tolerance\": 7,\n",
        "            \"Fertility\": 8, \"Calving Ease\": 9, \"Mothering Ability\": 8, \"Temperament\": 8, \"Grazing Ability\": 8,\n",
        "            \"Strength\": 9, \"Longevity\": 12, \"Climate Adaptability\": 9\n",
        "        },\n",
        "        \"genetic_distance\": {\"Brahman\": 50, \"Sahiwal\": 160, \"Fresian\": 200, \"Cholistani\": 170}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Updated breed identification function using trained model\n",
        "def identify_breed(image):\n",
        "    # Preprocess the image\n",
        "    img = image.resize((224, 224))  # Match model input size\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict using the trained model\n",
        "    predictions = model.predict(img_array)\n",
        "    breed_index = np.argmax(predictions[0])  # Get index of highest probability\n",
        "    confidence = predictions[0][breed_index]  # Confidence score\n",
        "    breed = class_labels[breed_index]  # Map index to breed name\n",
        "\n",
        "    # Check if breed exists in breed_data, fallback to \"Unknown\" if not\n",
        "    if breed not in breed_data:\n",
        "        return \"Unknown\", confidence\n",
        "    return breed, confidence\n",
        "\n",
        "# Predict traits with confidence intervals\n",
        "def predict_traits(parent1_traits, parent2_traits):\n",
        "    offspring_traits = {}\n",
        "    for trait in parent1_traits:\n",
        "        avg = (parent1_traits[trait] + parent2_traits[trait]) / 2\n",
        "        ci = 1.0\n",
        "        offspring_traits[trait] = (avg, [avg - ci, avg + ci])\n",
        "    return offspring_traits\n",
        "\n",
        "# Simulate multi-generation breeding\n",
        "def simulate_breeding(parent1, parent2, generations=3):\n",
        "    gen_traits = []\n",
        "    current_traits = predict_traits(breed_data[parent1][\"traits\"], breed_data[parent2][\"traits\"])\n",
        "    gen_traits.append({trait: val[0] for trait, val in current_traits.items()})\n",
        "\n",
        "    for i in range(generations - 1):\n",
        "        next_parent = \"Friesian\" if i == 0 else \"Brahman\"\n",
        "        next_gen = predict_traits({trait: val[0] for trait, val in current_traits.items()}, breed_data[next_parent][\"traits\"])\n",
        "        gen_traits.append({trait: val[0] for trait, val in next_gen.items()})\n",
        "        current_traits = next_gen\n",
        "    return gen_traits\n",
        "\n",
        "# Custom Chatbot Logic with Gemini Integration\n",
        "def get_chatbot_response(user_input, identified_breed):\n",
        "    user_input = user_input.lower().strip()\n",
        "\n",
        "    # Check for specific breed info\n",
        "    if \"breed\" in user_input:\n",
        "        return f\"The identified breed is {identified_breed}.\"\n",
        "    elif \"color\" in user_input:\n",
        "        return f\"The color of {identified_breed} is {breed_data[identified_breed]['color']}.\"\n",
        "    elif \"weight\" in user_input:\n",
        "        return f\"The average weight of {identified_breed} is {breed_data[identified_breed]['weight']} kg.\"\n",
        "    elif \"height\" in user_input:\n",
        "        return f\"The average height of {identified_breed} is {breed_data[identified_breed]['height']} cm.\"\n",
        "    elif \"milk production\" in user_input:\n",
        "        return f\"The milk production of {identified_breed} is {breed_data[identified_breed]['traits']['Milk Production']} units.\"\n",
        "    elif \"disease resistance\" in user_input:\n",
        "        return f\"The disease resistance of {identified_breed} is {breed_data[identified_breed]['traits']['Disease Resistance']} out of 10.\"\n",
        "    elif \"heat tolerance\" in user_input:\n",
        "        return f\"The heat tolerance of {identified_breed} is {breed_data[identified_breed]['traits']['Heat Tolerance']} out of 10.\"\n",
        "\n",
        "    # Compare breeds\n",
        "    elif \"compare\" in user_input:\n",
        "        match = re.search(r\"compare\\s+(\\w+)\\s+and\\s+(\\w+)\", user_input)\n",
        "        if match:\n",
        "            breed1, breed2 = match.groups()\n",
        "            if breed1 in breed_data and breed2 in breed_data:\n",
        "                return f\"Comparing {breed1} and {breed2}:\\n\" \\\n",
        "                       f\"{breed1} Milk Production: {breed_data[breed1]['traits']['Milk Production']}, \" \\\n",
        "                       f\"{breed2} Milk Production: {breed_data[breed2]['traits']['Milk Production']}\\n\" \\\n",
        "                       f\"{breed1} Weight: {breed_data[breed1]['weight']} kg, \" \\\n",
        "                       f\"{breed2} Weight: {breed_data[breed2]['weight']} kg\\n\" \\\n",
        "                       f\"{breed1} Height: {breed_data[breed1]['height']} cm, \" \\\n",
        "                       f\"{breed2} Height: {breed_data[breed2]['height']} cm\"\n",
        "            else:\n",
        "                return \"One or both breeds not found in the database.\"\n",
        "        return \"Please specify breeds to compare, e.g., 'compare Sahiwal and Friesian'.\"\n",
        "\n",
        "    # Best breed for a trait\n",
        "    elif \"best\" in user_input:\n",
        "        if \"milk\" in user_input:\n",
        "            best_breed = max(breed_data.items(), key=lambda x: x[1][\"traits\"][\"Milk Production\"])[0]\n",
        "            return f\"The best breed for milk production is {best_breed} with {breed_data[best_breed]['traits']['Milk Production']} units.\"\n",
        "        elif \"disease\" in user_input:\n",
        "            best_breed = max(breed_data.items(), key=lambda x: x[1][\"traits\"][\"Disease Resistance\"])[0]\n",
        "            return f\"The best breed for disease resistance is {best_breed} with {breed_data[best_breed]['traits']['Disease Resistance']} out of 10.\"\n",
        "        elif \"heat\" in user_input:\n",
        "            best_breed = max(breed_data.items(), key=lambda x: x[1][\"traits\"][\"Heat Tolerance\"])[0]\n",
        "            return f\"The best breed for heat tolerance is {best_breed} with {breed_data[best_breed]['traits']['Heat Tolerance']} out of 10.\"\n",
        "        return \"Please specify what trait to find the best breed for, e.g., 'best for milk production'.\"\n",
        "\n",
        "    # Fallback to Gemini API for general queries\n",
        "    try:\n",
        "        prompt = f\"Answer as a cattle breeding expert: {user_input}\"\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Sorry, I couldn't process your request due to an error: {str(e)}. Please try again.\"\n",
        "\n",
        "# Streamlit app\n",
        "st.set_page_config(page_title=\"Cattle Breeding Assistant\", layout=\"wide\")\n",
        "st.title(\"Cattle Breeding Assistant\")\n",
        "\n",
        "# Sidebar for inputs\n",
        "st.sidebar.header(\"Input Parameters\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload a cow photo\", type=[\"jpg\", \"png\"])\n",
        "location = st.sidebar.text_input(\"Farm Location\", \"India\")\n",
        "generations = st.sidebar.slider(\"Number of Generations to Simulate\", 1, 5, 3)\n",
        "timeframe = st.sidebar.slider(\"Breeding Plan Timeframe (Months)\", 6, 24, 12)\n",
        "breeding_goal = st.sidebar.selectbox(\"Primary Breeding Goal\", [\"Balanced Improvement\", \"Milk Production\", \"Disease Resistance\"])\n",
        "\n",
        "# Main content\n",
        "col1, col2 = st.columns([2, 1])  # Split layout into two columns\n",
        "\n",
        "with col1:\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption=\"Uploaded Cow Photo\", use_column_width=True)\n",
        "\n",
        "        # Breed Identification\n",
        "        breed, confidence = identify_breed(image)\n",
        "        st.header(\"Breed Identification\")\n",
        "        st.write(f\"**Breed**: {breed}\")\n",
        "        st.write(f\"**Confidence**: {confidence * 100:.2f}%\")\n",
        "\n",
        "        # Check if breed is \"Unknown\" and handle accordingly\n",
        "        if breed == \"Unknown\":\n",
        "            st.warning(\"This breed is not in our database. Showing limited information.\")\n",
        "        else:\n",
        "            # Physical Characteristics\n",
        "            st.header(\"Physical Characteristics\")\n",
        "            st.write(f\"**Color**: {breed_data[breed]['color']}\")\n",
        "            st.write(f\"**Estimated Weight**: {breed_data[breed]['weight']} kg\")\n",
        "            st.write(f\"**Estimated Height**: {breed_data[breed]['height']} cm\")\n",
        "\n",
        "            # Trait Analysis\n",
        "            st.header(\"Trait Analysis\")\n",
        "            traits = breed_data[breed][\"traits\"]\n",
        "            trait_df = pd.DataFrame.from_dict(traits, orient=\"index\", columns=[\"Value\"])\n",
        "            st.dataframe(trait_df)\n",
        "\n",
        "            # Genetic Lineage\n",
        "            st.header(\"Genetic Lineage Visualization\")\n",
        "            genetic_distance = breed_data[breed][\"genetic_distance\"]\n",
        "            genetic_df = pd.DataFrame.from_dict(genetic_distance, orient=\"index\", columns=[\"Years\"])\n",
        "            st.dataframe(genetic_df)\n",
        "\n",
        "            # Plot genetic lineage\n",
        "            fig = go.Figure()\n",
        "            for other_breed, years in genetic_distance.items():\n",
        "                fig.add_trace(go.Scatter(x=[0, years], y=[0, 0], mode=\"lines+markers\", name=other_breed))\n",
        "            fig.update_layout(title=\"Genetic Distance (Years Since Common Ancestor)\", xaxis_title=\"Years\", yaxis_title=\"Distance\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Environmental Impact\n",
        "            st.header(\"Environmental Impact\")\n",
        "            st.write(f\"**Location**: {location}\")\n",
        "            st.write(f\"**Climate Adaptation Score**: 48.8/10\")\n",
        "            st.write(f\"**Annual Carbon Footprint**: 2,083 kg CO2e\")\n",
        "\n",
        "            # Market Impact\n",
        "            st.header(\"Market Impact Analysis\")\n",
        "            st.write(f\"**Estimated Annual Profit**: $3,773.42\")\n",
        "            financial_breakdown = {\"Milk Income\": 89, \"Health Savings\": 11, \"Feed Costs\": 0.418}\n",
        "            financial_df = pd.DataFrame.from_dict(financial_breakdown, orient=\"index\", columns=[\"Percentage\"])\n",
        "            fig = px.pie(financial_df, values=\"Percentage\", names=financial_df.index, title=\"Financial Breakdown\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Trait Improvement Targets\n",
        "            st.header(\"Trait Improvement Targets\")\n",
        "            improvement_targets = {\n",
        "                \"Strength\": 7, \"Milk Production\": 8, \"Disease Resistance\": 8,\n",
        "                \"Temperament\": 7, \"Heat Tolerance\": 6, \"Cold Tolerance\": 8\n",
        "            }\n",
        "            improvement_df = pd.DataFrame.from_dict(improvement_targets, orient=\"index\", columns=[\"Target\"])\n",
        "            fig = px.bar(improvement_df, x=improvement_df.index, y=\"Target\", title=\"Trait Improvement Targets\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # AI-Generated Breeding Plan\n",
        "            st.header(\"AI-Generated Breeding Plan\")\n",
        "            st.write(f\"**Timeframe**: {timeframe} months\")\n",
        "            st.write(f\"**Primary Goal**: {breeding_goal}\")\n",
        "            st.write(\"**Plan**: Cross Sahiwal with Kankrej in Month 1, monitor heat tolerance; cross offspring with Friesian in Month 6 to boost milk production.\")\n",
        "\n",
        "            # Multi-Generation Simulation\n",
        "            st.header(\"Multi-Generation Breeding Simulation\")\n",
        "            parent2 = \"Kankrej\"\n",
        "            gen_traits = simulate_breeding(breed, parent2, generations)\n",
        "            for i, gen in enumerate(gen_traits):\n",
        "                st.subheader(f\"Generation {i+1}\")\n",
        "                st.write(f\"**Parents**: {breed} x {parent2 if i == 0 else 'Friesian' if i == 1 else 'Brahman'}\")\n",
        "                st.write(\"**Predicted Traits**:\")\n",
        "                st.json(gen)\n",
        "\n",
        "            # Trait Evolution Forecast\n",
        "            st.header(\"Trait Evolution Forecast\")\n",
        "            evolution_data = {\n",
        "                \"Generation\": [0, 1, 2, 3],\n",
        "                \"Milk Production\": [6.5, 6.5, 7.0, 9.0],\n",
        "                \"Strength\": [7.5, 7.5, 7.8, 8.1],\n",
        "                \"Fertility\": [7.8, 7.8, 7.5, 9.1],\n",
        "                \"Longevity\": [8.0, 8.0, 8.2, 10.0]\n",
        "            }\n",
        "            evolution_df = pd.DataFrame(evolution_data)\n",
        "            fig = go.Figure()\n",
        "            for trait in [\"Milk Production\", \"Strength\", \"Fertility\", \"Longevity\"]:\n",
        "                fig.add_trace(go.Scatter(x=evolution_df[\"Generation\"], y=evolution_df[trait], mode=\"lines+markers\", name=trait))\n",
        "            fig.update_layout(title=\"Trait Evolution Forecast\", xaxis_title=\"Generations\", yaxis_title=\"Trait Value\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Comprehensive Trait Comparison\n",
        "            st.header(\"Comprehensive Trait Comparison\")\n",
        "            comparison_traits = [\"Fertility\", \"Disease Resistance\", \"Climate Adaptability\", \"Feed Efficiency\", \"Temperament\", \"Longevity\", \"Strength\"]\n",
        "            sahiwal_traits = [9, 10, 10, 1.5, 9, 14, 9]\n",
        "            kankrej_traits = [9, 9, 10, 1.4, 8, 13, 10]\n",
        "            offspring_traits = [9, 9, 10, 1.4, 8, 13, 9]\n",
        "\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Scatterpolar(r=sahiwal_traits, theta=comparison_traits, fill=\"toself\", name=\"Sahiwal\"))\n",
        "            fig.add_trace(go.Scatterpolar(r=kankrej_traits, theta=comparison_traits, fill=\"toself\", name=\"Kankrej\"))\n",
        "            fig.add_trace(go.Scatterpolar(r=offspring_traits, theta=comparison_traits, fill=\"toself\", name=\"Predicted Offspring\"))\n",
        "            fig.update_layout(title=\"Comprehensive Trait Comparison\", polar=dict(radialaxis=dict(visible=True, range=[0, 14])))\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Trait Distribution (Sunburst Chart)\n",
        "            st.header(\"Trait Distribution\")\n",
        "            sunburst_data = {\n",
        "                \"labels\": [\"Production\", \"Milk Production\", \"Milk Fat\", \"Milk Protein\", \"Health\", \"Disease Resistance\", \"Adaptability\", \"Heat Tolerance\", \"Cold Tolerance\"],\n",
        "                \"parents\": [\"\", \"Production\", \"Production\", \"Production\", \"\", \"Health\", \"Health\", \"Adaptability\", \"Adaptability\"],\n",
        "                \"values\": [9, 12, 4.8, 3.5, 10, 10, 10, 10, 5]\n",
        "            }\n",
        "            sunburst_df = pd.DataFrame(sunburst_data)\n",
        "            fig = px.sunburst(sunburst_df, names=\"labels\", parents=\"parents\", values=\"values\", title=\"Trait Distribution for Sahiwal\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "with col2:\n",
        "    # Chatbot Section\n",
        "    st.header(\"Cattle Breeding Chatbot\")\n",
        "    st.write(\"Note : Only ask questions about the identified breed or cattle breeding!\")\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    # Chat input\n",
        "    user_input = st.text_input(\"Your question:\", key=\"chat_input\")\n",
        "    if st.button(\"Send\"):\n",
        "        if user_input:\n",
        "            response = get_chatbot_response(user_input, breed)\n",
        "            st.session_state.chat_history.append({\"user\": user_input, \"bot\": response})\n",
        "\n",
        "    # Display chat history\n",
        "    for chat in st.session_state.chat_history:\n",
        "        st.write(f\"**You**: {chat['user']}\")\n",
        "        st.write(f\"**Bot**: {chat['bot']}\")"
      ],
      "metadata": {
        "id": "h_tWyIBkO3jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e29c524-76e2-4e51-bf86-63aa28a101f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit --quiet"
      ],
      "metadata": {
        "id": "vmsALUeBPIHj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U40Ak0ohPIog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4334a1f8-9672-4754-e9ef-3752cbc1137a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.232.46.221:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0Kyour url is: https://fair-knives-speak.loca.lt\n",
            "2025-03-27 06:10:51.136 Uncaught exception GET /_stcore/stream (127.0.0.1)\n",
            "HTTPServerRequest(protocol='http', host='fair-knives-speak.loca.lt', method='GET', uri='/_stcore/stream', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/websocket.py\", line 938, in _accept_connection\n",
            "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/browser_websocket_handler.py\", line 177, in open\n",
            "    self._session_id = self._runtime.connect_session(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/runtime.py\", line 397, in connect_session\n",
            "    session_id = self._session_mgr.connect_session(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/websocket_session_manager.py\", line 99, in connect_session\n",
            "    session = AppSession(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 157, in __init__\n",
            "    self.register_file_watchers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 194, in register_file_watchers\n",
            "    self._local_sources_watcher = LocalSourcesWatcher(self._pages_manager)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 65, in __init__\n",
            "    self.update_watched_pages()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 77, in update_watched_pages\n",
            "    self._register_watcher(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 136, in _register_watcher\n",
            "    watcher=PathWatcher(filepath, self.on_file_changed),\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/event_based_path_watcher.py\", line 107, in __init__\n",
            "    path_watcher.watch_path(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/event_based_path_watcher.py\", line 185, in watch_path\n",
            "    folder_handler.watch = self._observer.schedule(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/api.py\", line 312, in schedule\n",
            "    emitter.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/utils/__init__.py\", line 75, in start\n",
            "    self.on_thread_start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify.py\", line 119, in on_thread_start\n",
            "    self._inotify = InotifyBuffer(path, recursive=self.watch.is_recursive, event_mask=event_mask)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_buffer.py\", line 30, in __init__\n",
            "    self._inotify = Inotify(path, recursive=recursive, event_mask=event_mask)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 185, in __init__\n",
            "    self._add_dir_watch(path, event_mask, recursive=recursive)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 411, in _add_dir_watch\n",
            "    self._add_watch(full_path, mask)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 424, in _add_watch\n",
            "    Inotify._raise_error()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 441, in _raise_error\n",
            "    raise OSError(err, os.strerror(err))\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Exception ignored in: <function AppSession.__del__ at 0x7d1e517b45e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 177, in __del__\n",
            "    self.shutdown()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 254, in shutdown\n",
            "    self.request_script_stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 426, in request_script_stop\n",
            "    if self._scriptrunner is not None:\n",
            "       ^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'AppSession' object has no attribute '_scriptrunner'\n",
            "2025-03-27 06:10:57.570581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743055857.602712   22704 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743055857.612959   22704 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-27 06:10:57.644881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-27 06:11:01.339604: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-03-27 06:11:41.970 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-03-27 06:13:22.155 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-03-27 06:13:43.764 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-03-27 06:15:04.601 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-03-27 06:16:17.756 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d1daede8a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d1daede8a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1757F9wMUnrhtjtuvABmi4kQkPHrhWl0s",
      "authorship_tag": "ABX9TyNRu1Z8mgAvHOSsmivSVXGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}